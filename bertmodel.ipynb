{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1VYR0U5QkhH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tKGmPQGValt",
        "outputId": "352985a3-5a9d-4772-87a2-5506ba365177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igawz7-bHaKx",
        "outputId": "40d9def5-7f89-4f33-ed53-fa471198b04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxCUGV9xW4Qr",
        "outputId": "9a54d5c7-34ff-453b-ee2e-9b1d1d0c36d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzbTvvf3W6m-",
        "outputId": "eafb715c-7fa7-460c-eeb6-1fac96e92439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buZdVlKMQozz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "4044e24c-2b2a-4bca-8bd8-29d2694d2457"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2560c8368a05>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/text_label_sentiment.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/text_label_sentiment.csv'"
          ]
        }
      ],
      "source": [
        "news = pd.read_csv('/content/text_label_sentiment.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqxlYDVtQspp"
      },
      "outputs": [],
      "source": [
        "news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHGnC2nkQuJT"
      },
      "outputs": [],
      "source": [
        "news.drop(['Unnamed: 0','sentiment'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U460JPMkRJt5"
      },
      "outputs": [],
      "source": [
        "news.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF86y0VwScrt"
      },
      "outputs": [],
      "source": [
        "news.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEcmeY4JSRqv"
      },
      "outputs": [],
      "source": [
        "hindi_stopwords = [\n",
        "    'अपना', 'अपनी', 'अपने', 'अभी', 'आदि', 'इस', 'इसके', 'इसको', 'इसमें', 'इससे',\n",
        "    'उनका', 'उनकी', 'उनके', 'उनको', 'उनका', 'उनकी', 'उनके', 'उनको', 'उन्हें', 'उसका',\n",
        "    'उसकी', 'उसके', 'उसको', 'उसमें', 'उसने', 'उसी', 'उसे', 'उसका', 'करता', 'करते',\n",
        "    'करना', 'करने', 'करें', 'कहते', 'कहा', 'का', 'कारण', 'किसी', 'की', 'कुछ', 'के',\n",
        "    'को', 'कोई', 'कौन', 'कौनसा', 'गया', 'घर', 'जब', 'जहाँ', 'जा', 'जितना', 'जिन',\n",
        "    'जिन्होंने', 'जिन्हों', 'जिस', 'जिसे', 'जी', 'जिसके', 'जिसको', 'जिसमें', 'जिसे', 'तक',\n",
        "    'तब', 'तरह', 'तिन', 'तिन्हें', 'तिन्हों', 'तिस', 'तिसे', 'था', 'थे', 'दिया', 'दूसरे',\n",
        "    'दो', 'द्वारा', 'ने', 'पर', 'पहले', 'पूरा', 'पूरी', 'फिर', 'बनी', 'बहुत', 'बाद',\n",
        "    'बाला', 'भी', 'मगर', 'मानो', 'मैं', 'मैंने', 'में', 'यदि', 'यह', 'यहाँ', 'यही',\n",
        "    'या', 'यिह', 'ये', 'रखें', 'रहा', 'रहे', 'लिए', 'लिया', 'लेकिन', 'व', 'वगेरह', 'वर्ग',\n",
        "    'वह', 'वहाँ', 'वही', 'वाले', 'वाली', 'वाला', 'वाले', 'वाली', 'वाला', 'वाले', 'वाली',\n",
        "    'वाला', 'सबसे', 'सबसे', 'सकता', 'सकते', 'सकती', 'सकती', 'सब', 'सबसे', 'से', 'ही',\n",
        "    'है', 'हैं', 'हुआ', 'हुई', 'हुए', 'हो', 'होता', 'होते', 'होती', 'होती', 'होते', 'होते',\n",
        "    'होती', 'होती', 'होती', 'होना', 'होने', 'अंदर', 'अदि', 'अन्य', 'अप', 'अफ', 'अल', 'अलब',\n",
        "    'अव', 'अवश्य', 'अस', 'आदि', 'आप', 'आपका', 'आपकी', 'आपके', 'आपने', 'आपने', 'आदि', 'आना',\n",
        "    'इंहोंने', 'इंहें', 'इंहों', 'इतना', 'इतनी', 'इतने', 'इन', 'इनका', 'इनकी', 'इनके', 'इन्ही',\n",
        "    'इन्होंने', 'इन्हें', 'इन्हों', 'इस', 'इसका', 'इसकी', 'इसके', 'इसी', 'उंहोंने', 'उंहें',\n",
        "    'उंहों', 'उपर', 'उसके', 'उससे', 'उसी', 'उसे', 'उसी', 'उसे', 'कर', 'करत', 'करता', 'करती',\n",
        "    'करते', 'करन', 'करना', 'करने', 'किया', 'किये', 'किये', 'किया', 'कुछ', 'कुल', 'के', 'को', 'को'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22SnTBMtVVFT",
        "outputId": "90ed6393-a061-4b61-db20-9f1a9733a2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/indian.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download(\"indian\")\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "def remove_hindi_stopwords(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    cleaned_words = []\n",
        "    for word in words:\n",
        "        # Remove specific words\n",
        "        if word.lower() not in hindi_stopwords:\n",
        "            # Remove English words and special characters\n",
        "            if not re.match(\"^[A-Za-z]*$\", word) and not bool(re.search(r'[0-9०-९]', word)):\n",
        "                # Specify special characters to remove (e.g., @, ., ,, #, &)\n",
        "                word = re.sub(r'[.,@#&]', '', word)\n",
        "                cleaned_words.append(word)\n",
        "    return ' '.join(cleaned_words)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q58XcadVf_V"
      },
      "outputs": [],
      "source": [
        "news['text']=news['text'].apply(str)\n",
        "\n",
        "news['text'] = news['text'].apply(remove_hindi_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkVmVFqgl8QZ"
      },
      "outputs": [],
      "source": [
        "news['title']=news['title'].apply(str)\n",
        "\n",
        "news['title'] = news['title'].apply(remove_hindi_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXNLSN6BofRp",
        "outputId": "dff810c0-8baa-4b64-8dc0-27d2e19ef838"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       हाउस डिम एड : हमने जेसन चैफेट ट्वीट कॉमी पत्र ...\n",
              "1       फ्लिन : हिलेरी क्लिंटन  कैंपस बड़ी महिला - ब्र...\n",
              "2                                   सत्य क्यों आपको निकाल\n",
              "3       एकल अमेरिकी हवाई हमले मारे गए नागरिकों पहचान ल...\n",
              "4       ईरानी महिला व्यभिचार मौत घाट उतारने महिला बारे...\n",
              "                              ...                        \n",
              "2050    मडावो पोसबिलिटी ट्रम्प  कैंपेन इनोसेंट और ' स्...\n",
              "2051    जॉन किर्बी अंतिम दिन : हापलेस स्टेट रेप स्वामि...\n",
              "2052    बड़ा खुलासा ! ममता बनर्जी ब्लैक मनी मोदी हमला ...\n",
              "2053    एक संघर्ष थीम पार्क पूछता : क्या सांता विश्वास...\n",
              "2054    वीडियो  सैक्रामेंटो पुलिस कार हिट कार हिट मैन ...\n",
              "Name: title, Length: 2055, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "news['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qrj_0p5vRSS5"
      },
      "outputs": [],
      "source": [
        "#split train test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test, labels, y_test = train_test_split(news['text'], news['label'], test_size=0.2, stratify=news['label'],random_state=123, shuffle=True)\n",
        "\n",
        "sentences = train.values\n",
        "labels=labels.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ORscGztR_Go",
        "outputId": "9b7b10a8-60c5-4284-d838-c4ed7a5f98db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['“ : – – ” – – wing-men',\n",
              "       '’ — ( ) — “ ‘ ’ ” — “ ! ! ! ” “ ” — “ — ! ” — : “ ? ” ? “ ’ ” “ ” “ ” “ ” : “ ’ ” “ ! ” ” ’ ” “ ” “ ” — “ ” — ’ “ ” “ ” ’ : ’ — — “ ” : — — : ’ ’ ’ “ ” — “ ” : ’ “ ” ’ ’ — “ ” “ ” : “ ” ’ “ ” “ ” ’ “ ” — — ’ “ ” ’ “ ” “ ’ ” “ ’ ” “ ’ ” “ ” — ’ “ ” “ ” ’ ’ ’ : “ ’ ” “ ” “ ’ ” “ ” — “ ” — “ ’ ” “ ” “ ” “ ’ “ — — — “ ” “ ” : “ ! ” — — “ ” ’ ’ “ ” : “ ” ’ “ ” “ ‘ ? ’ ‘ ’ ‘ ’ ’ ” “ ’ ”',\n",
              "       '- इराकी बलों मोसुल हासिल कोशिश मंगलवार शहर पश्चिमी हिस्से प्रवेश इस्लामिक स्टेट आतंकवादियों साथ भारी झड़पों दौरान एक पुल और कई सार्वजनिक इमारतों बना दिया। नागरिकों बताया कि फरवरी बमबारी और गोलाबारी भारी थी शहर पश्चिमी हिस्से चलाने ऑपरेशन शुरुआत - देश जहां लगभग एक मिलियन लोग फंस गए और हताश परिस्थितियों रह हैं। सैनिकों केंद्रीय बैंक एक शाखा हटा एक पुरातात्विक संग्रहालय शहर ले जाने जिहादियों तोड़फोड़ थी और शहर केंद्र तिगरी नदी पार हुरिया ब्रिज। एक सैन्य प्रवक्ता जनरल याहया रसूल फोन करके कहा। उन्होंने `` हम मोसुल आजाद नहीं करेंगे हम नहीं रुकेंगे। `` संघीय पुलिस प्रमुख लेफ्टिनेंट जनरल राएद शाकिर जवादत कि सुरक्षा बलों एक सरकारी परिसर हटा था। गठबंधन सेनाओं एक बयान इराकियों सहायता मिली और प्रगति एक समान विवरण गया। संग्रहालय इस्लामिक स्टेट आतंकवादियों जब्त किए जाने दुनिया भर ध्यान केंद्रित संग्रह कलाकृतियों नष्ट स्लेजहेमर और ड्रिल उपयोग था। विनाश दुनिया भर विद्वानों भयभीत दिया। आंतरिक मंत्रालय सैनिकों एक कुलीन इकाई प्रवक्ता लेफ्टिनेंट जनरल अब्दुल आमिर कि इस्लामिक स्टेट ओर बनाए गए भवनों एक प्रांगण शामिल जहां उग्रवादियों व्हिपिंग पत्थरबाजी और हाथापाई घटनाओं अंजाम साथ एक इमारत जहां आतंकवादियों लोगों फेंक मृत्यु लिए। जनरल मुहम्मदवी एक साक्षात्कार `` सरकारी परिसर मुक्ति हमारे बलों एक महत्वपूर्ण कदम जो हमारे एक महत्वपूर्ण प्रेरक स्थिति है। `` “ अंतरराष्ट्रीय गठबंधन हवाई हमले और ड्रोन शहर मुक्ति गति देने एक प्रमुख भूमिका निभाई है। “ स्पष्ट नहीं कि लाभ कितना स्थायी होगा। हालांकि सैनिकों सरकारी परिसर इराकी झंडा उठाया दावासा पड़ोस इस्लामिक स्टेट आतंकवादियों भारी आग तहत पीछे हटने मजबूर एसोसिएटेड प्रेस बताया। संग्रहालय इस्लामिक स्टेट स्नाइपर्स सीमा भीतर बना जिससे एक पलटवार चपेट आ गया। इस्लामिक स्टेट जुड़े सोशल मीडिया अकाउंट्स बताया कि उग्रवादियों आक्रामक हमले दौरान तीन आत्मघाती बम बनाए थे। हालांकि सैन्य अग्रिम दस वर्ष सरकारी बलों कि मंगलवार पश्चिमी मोसुल हासिल सप्ताहिक हमले महत्वपूर्ण क्षण प्रतिनिधित्व किया। लड़ाई शहर अधिकांश हवाई अड्डे शामिल आसान नहीं था। इराकी बलों पूर्वी मोसुल नियंत्रण हासिल तीन महीने अधिक समय लग और वहां भारी जनहानि हुई। प्रधान मंत्री हैदर और देश सशस्त्र बलों प्रमुखों एक बयान अनुसार `` सुरक्षा बलों प्रगति समीक्षा `` मंगलवार मोसुल बाहर आक्रामक जिम्मेदार संचालन कमान मुख्यालय दौरा किया। हुर्रिया स्वतंत्रता पुल सरकारी बलों वापस जाने पांच पुलों दूसरा है। मोसुल आतंकवादियों अलग-थलग पिछले साल हवाई हमले सभी पांच पुलों क्षतिग्रस्त दिया। मोसुल जून देश उत्तर और पश्चिम बड़े हिस्सों साथ इस्लामिक स्टेट गिर गया। इराकी जनसंख्या केंद्र आंशिक रूप आतंकवादी समूह नियंत्रण है। मानवीय मामलों समन्वय संयुक्त राष्ट्र कार्यालय मंगलवार बताया कि मोसुल फरवरी लेकर अब लगभग लोग विस्थापित चुके हैं। अकेले शुक्रवार सहित - अक्टूबर नागरिक उच्चतम निरंतर विस्थापन में। संयुक्त राष्ट्र कार्यालय `` पश्चिमी मोसुल विस्थापित सभी लोगों तो परिवार सदस्यों साथ शिविरों आपातकालीन स्थलों समायोजित जहां एक टेंटेड प्लॉट बुनियादी घरेलू आपूर्ति स्वच्छता किट और भोजन राशन मिलता है। `` कार्यालय निर्माण मोसुल दक्षिण शिविर निर्माण और पानी और स्वच्छता सेवाओं स्थापना तहत है। फरवरी कार्यालय घावों अधिक लोगों इलाज जिनमें लोग शामिल जिन्हें एक स्पष्ट हमले इलाज मोसुल पूर्व शहर एरबिल अस्पताल भर्ती कराया था। पूर्वी मोसुल कई पीने पानी कमी अधिकारियों चेतावनी दी और शहर दक्षिणी और पश्चिमी हिस्सों कई लोग अनुपचारित पानी पी जिससे बीमारियों प्रसार है।',\n",
              "       ...,\n",
              "       'पुन : बकवास कहती : वैचारिक असहमति व्यक्तिगत रूप नहीं लेना अच्छा व्यक्तिगत रूप बजे ; नही। गंदगी नहीं करता। दाऊ : मेरे थोड़ा हटके लग हैं। बस तुम्हारे देख हूँ। मुझे परवाह है। बजे ; क्या विरोध ? केवल मुझे उस अवधि शुरू जहां जीवन कई खराब चीजों अनुभव ईमानदार आपको मुझे जानने एक मजबूत आधार रेखा नहीं और अधिकांश साल लगते : बस एक अंतर्ज्ञान बजे ; जीवन बीच अंतर अब कठिन और जीवन कठिन ; जानना चाहते कि मेरा क्या मतलब उम्मीद नहीं कि किया। जीवन सभी रूपों समान क्षमता और मूल्य देखता हूं। मानवता प्रजातियों तुलना बेहतर बदतर नहीं देखता और अगर मुझे चीज़ `` प्रतिभा `` श्रेय जाता तो उस भावना होगा जो मानव शरीर साथ बांधती है। मुझे नहीं लगता कि इसे प्रतिक्रिया भावनात्मक थी क्योंकि मतलब नहीं था। लगता कि कैसा महसूस हूं जो हूं। एक तर्क न तो हमारे विचारों बदलता और हम वास्तविक जीवन कैसे कार्य हैं। इसलिए व्यावहारिकता और अनुभवजन्य घटना बारे जोड़ना। अगर चीजें वास्तविक जीवन नहीं बदलती तो बहस बात नहीं देखता। बजे ; बाहर और लगभग बजे : विचारों आदान-प्रदान एक मूल्य भले मूल राय बदल न दें परिप्रेक्ष्य ; कि दूसरों साथ एक धारणा हावी उस बजे दूर : क्यों ? ; क्यों नहीं साथ शुरू : क्या राय नहीं कही ? मेरा होगा पूर्वाह्न ; मेरे लागत लाभ विश्लेषण आम तौर ऐसा कि चर्चाएँ संभावित लाभ तुलना अधिक जोखिम लेती : देखिए मुझे ऐसा बिल्कुल नहीं लगता। ठीक विपरीत महसूस हूं। मुझे हमेशा लगता कि दूसरों बारे जानने खुले तो कभी व्यर्थ चर्चा नहीं ; सभी रिश्तों समान वजन नहीं दे सभी खुला नहीं ध्यान बात देना चाहिए कि जीवन ज्यादा क्या : ठीक हाँ उन लोगों प्राथमिकता देते जो अधिक गिनती आपको दूसरों बात जरूरत नहीं ; मेरा मतलब कि चीजें अधिक व्यापक रूप सिद्धांत रूप ली गई और मिनट नीचे हैं। यादृच्छिक लोगों साथ यादृच्छिक चर्चा समय बिताया तो शायद मेरे पास चर्चा समय और ऊर्जा और जो लोग मेरे जीवन यादृच्छिक नहीं अकेले उन लोगों यादृच्छिक न दें। : असहमत हूं। मुझे लगता कि यादृच्छिक अजनबियों और महत्वपूर्ण लोगों साथ विचार-विमर्श समय है। हम वैसे सारा समय ऑनलाइन बिताते हम उतना समय कमा हम सार्थक खर्च हैं। खूब सोशल मीडिया ब्राउज़ बिल्कुल बातचीत न करें। हम अजनबी हम एक वास्तविक सामाजिक दायरे हैं। कम महत्वपूर्ण बातचीत सामना पड़ता क्या समय नहीं और क्या अर्थहीन ? आईएमओ नं। ; गलत समझ गए। कि और बोलूं उन लोगों भाग्य एक नज़र डालें जिन्हें जानते हैं। चाहते तो उन सभी एकरूपता नहीं चुन सकते। : यकीन मतलब नहीं कि उन लोगों मेरे मतलब नहीं कि पूर्वाह्न लिखता हूं ; बारे नहीं खासकर मामले चर्चा / बातचीत ध्यान केंद्रित हैं। अगर बाहर निकलने दूसरों देखभाल अधिक समझ प्रतिनिधित्व है। : कैसे ? पूर्वाह्न ; एक असहमति माध्यम लोगों कष्ट देकर : असहमति ज्ञानवर्धक है। जैसा कि सूरज त्ज़ु हम उन लोगों असहमत जो अक्सर ज्यादा सिखाते हैं। मुझे लगता कि दूसरों परिप्रेक्ष्य समझना महत्वपूर्ण है। कठिनाई चर्चा और असहमति नहीं कि सत्य कैसे पाया जाता है। उन लोगों बचते जो साथ असहमत तो आसानी एक संज्ञानात्मक पतन शिकार जाते पुष्टि पूर्वाग्रह पूर्वाह्न जाता ; नोट कि लागत लाभ विश्लेषण पहले। जोखिम बढ़िया और लोग गर्म जाते और दोस्ती टूट जाती है। कहता हूं कि स्वयं मित्रों सहित अवलोकन और कहता हूं कि मेरे संबंध अनुभव से। ___ एक तर्क कि ऐसा चीज़ दृष्टिकोण नहीं बदला होगा न मेरा बदला होगा। अब विचार नहीं बदला और मुझे नहीं बदला है। : अच्छी मूर्खतापूर्ण ___। मुझे लगता कि बौद्धिक साथियों जानने ज़रूरत कि विचारों भावनाओं और मित्रता कैसे अलग जाए और कमरे लोग अधिक सक्षम हैं। क्या ? पेज',\n",
              "       \"अक्टूबर जबकि पश्चिमी प्रेस `` रूसी आक्रामकता `` जनता डराना जारी रखा और अमेरिकी राष्ट्रपति चुनावों प्रभावित रूस दोषी ठहराया व्लादिमीर पुतिन केवल एक भाषण जो मुख्यधारा मीडिया दिखाई देने संभावना नहीं है। फेसबुक सांझा अक्टूबर सोची वल्दाई क्लब विशेषज्ञों बैठक पुतिन अमेरिकी चुनावों बारे : `` विभिन्न उम्मीदवारों प्लेटफार्मों एक नज़र धारणा देती कि वे एक साँचे बने - अंतर मामूली अगर भी। `` पुतिन `` रूसी हैकिंग द यूएस इलेक्शन कहानियों `` `` पौराणिक और काल्पनिक समस्या `` और `` हिस्टीरिया `` रूप जो कि अमेरिकी राष्ट्रपति चुनाव रूसी ध्यान भटकाने बजाय संयुक्त राज्य अमेरिका मारी बजाय घरेलू मुद्दों ध्यान दिए : “ संयुक्त राज्य अमेरिका जरूरी समस्याएं ऐसा लगता कि भारी सार्वजनिक ऋण लेकर आग्नेयास्त्रों हिंसा वृद्धि और पुलिस मनमानी कार्रवाई मामले शामिल हैं। आपको लगता कि चुनावी बहस और अनसुलझे समस्याओं ध्यान केंद्रित करेगी कुलीन पास ऐसा नहीं जो समाज आश्वस्त करे ऐसा लगता और इसलिए रूसी हैकर्स जासूसों प्रभाव एजेंटों इंगित बजाय जनता ध्यान भटकाने प्रयास हैं। इत्यादि। `` `` क्या गंभीरता कल्पना कि रूस अमेरिकी लोगों पसंद प्रभावित ? `` अमेरिका केला रिपब्लिक ’ नहीं आखिरकार एक बड़ी शक्ति है। अगर गलत हूं तो मुझे सुधारो। पुतिन हमें याद दिलाया कि असली शासक : `` सुपरनेचुरल ऑलिगार्की एंड ब्यूरोक्रेसी विस्तार जो वास्तव अक्सर समाज निर्वाचित और नियंत्रित नहीं बहुसंख्यक नागरिक जो सरल और सादा चीजें चाहते - स्थिरता देशों स्वतंत्र विकास जीवन संभावनाएं। `` बच्चों जीवन सांस्कृतिक पहचान संरक्षित और अंत और प्रियजनों बुनियादी सुरक्षा। ” अमीर और गरीबों बीच बढ़ती खाई कम पश्चिमी कुलीनों जिक्र पुतिन : “ ऐसा लगता जैसे कि कुलीन समाज गहरे स्तरीकरण और मध्यम क्षरण नहीं देखते जबकि एक समय वे वैचारिक विचारों आरोपण जो कि मेरी राय सांस्कृतिक और राष्ट्रीय पहचान विनाशकारी हैं। और मामलों देशों वे राष्ट्रीय हितों तोड़ते और सुजैन पक्ष संप्रभुता त्याग हैं। `` पुतिन सभी याद दिलाया कि विश्व अस्थिरता वर्तमान स्थिति शीत युद्ध समाप्ति संयुक्त राज्य अमेरिका किए गए विकल्प एक सीधा परिणाम “ वैश्विक हितों और स्वयं हितों फिट केवल वैश्विक राजनीतिक और आर्थिक व्यवस्था लागू कोर्स। `` पाठ्यक्रम लेने अमेरिका वैश्वीकरण `` प्रकृति अधिक सामंजस्यपूर्ण और टिकाऊ `` बनाने मौका गंवा दिया। शीत युद्ध जीतने उत्साह संयुक्त राज्य अमेरिका `` अंतर्राष्ट्रीय जीवन अभिनेताओं साथ अनिवार्य रूप दृढ़ और समान बातचीत छोड़ सार्वभौमिक संस्थानों सुधार निर्माण नहीं फैसला और स्वयं संगठनों प्रसार तहत दुनिया लाने बजाय प्रयास किया। नियम और नियम। उन्होंने चुनिंदा लोगों और वैश्वीकरण और सुरक्षा रास्ता चुना। हर सहमत तैयार था। ” विजयी रवैये अंतर्राष्ट्रीय संबंधों व्यवस्था “ नियम और सिद्धांत अर्थव्यवस्था और राजनीति लगातार विकृत और हम अक्सर देखते कि कल केवल एक सच्चाई रूप और हठधर्मिता स्थिति उलट था। `` पश्चिमी पाखंड और दोहरी बात पुतिन : “ अगर आज जो शक्तियां लाभ मानक आदर्श पाती वे सभी अनुपालन मजबूर हैं। अगर कल समान मानक तरीके मिलते तो वे बिन फेंकने तेज अप्रचलित घोषित और नए नियमों सेट स्थापित प्रयास हैं। ” रूसी राष्ट्रपति अमेरिका नेतृत्व फैसले बारे याद दिलाया `` बेलग्रेड खिलाफ यूरोप केंद्र हवाई हमले शुरू और इराक और लीबिया `` और संयुक्त राज्य अमेरिका विदेश नीति एक उपकरण बदल : “ अफगानिस्तान परिचालन संयुक्त राष्ट्र सुरक्षा परिषद संबंधित निर्णय बिना शुरू हुआ। रणनीतिक संतुलन पक्ष स्थानांतरित इच्छा देशों अंतरराष्ट्रीय कानूनी ढांचे तोड़ जिसने नई मिसाइल रक्षा प्रणालियों तैनाती प्रतिबंधित दिया। उन्होंने आतंकवादी समूह बनाए और सशस्त्र किए जिनकी क्रूर कार्रवाइयों लाखों नागरिकों उड़ान भेजा लाखों विस्थापितों और आप्रवासियों बनाया और पूरे क्षेत्रों अराजकता बदल दिया। ” वैश्विक अर्थव्यवस्था बहुपक्षीय संस्थान हितों बढ़ावा देने एक उपकरण बन गए : “ हम देखते कि कैसे मुक्त व्यापार त्याग और देश प्रतिबंधों उपयोग राजनीतिक दबाव साधन रूप विश्व व्यापार संगठन दरकिनार और सख्त नियमों और बाधाओं साथ बंद आर्थिक गठजोड़ स्थापित प्रयास मुख्य लाभार्थी स्वयं अंतरराष्ट्रीय निगम हैं। और हम जानते कि है। वे देखते कि वे डब्ल्यूटीओ ढांचे भीतर सभी समस्याओं हल नहीं और इसलिए सोचते क्यों न नियमों और संगठन एक तरफ फेंक दें और बजाय एक नया निर्माण करें। `` हमेशा यूएस `` हमारे सहयोगियों `` रूप संदर्भित पुतिन जोर देकर कि वे `` आज दुनिया वास्तविक अंतरराष्ट्रीय समस्याओं हल इच्छा नहीं दिखाते हैं। `` ओएससीई बनाने बजाय `` सामान्य यूरोपीय और ट्रांस-अटलांटिक सुरक्षा सुनिश्चित एक महत्वपूर्ण तंत्र `` इसे `` विदेश नीति हितों सेवा एक साधन `` रूप आकार था। रूस लगातार विकेन्द्रीकरण और `` रूसी आक्रामकता `` ट्रम्पेटिंग बारे पुतिन : `` वे ' रूसी सैन्य खतरे ' जैसे खतरों काल्पनिक और पौराणिक खतरों मंथन जारी रखते हैं। `` एक लाभदायक व्यवसाय जिसका उपयोग रक्षा बजट नए पैसे पंप सहयोगी दलों एक महाशक्ति हितों झुकना नाटो विस्तार और बुनियादी सुविधाओं सैन्य इकाइयों और हथियारों हमारी सीमाओं करीब लाना है। बेशक नए बर्बर लोगों खिलाफ सभ्यता रक्षक रूप खुद चित्रित एक आकर्षक और यहां \\u200b\\u200bकि लाभदायक कार्य है। बात सिर्फ कि रूस हमला इरादा नहीं है। काफी बेतुका है। अकल्पनीय मूर्ख और अवास्तविक है। विचारों कल्पना बेतुका है। और वे राजनीतिक उद्देश्यों खोज विचारों उपयोग हैं। सवाल कि अगर नस चीजें जारी रहती तो दुनिया क्या इंतजार ? कल हमारे पास कैसी दुनिया होगी ? क्या हमारे पास स्थिरता सुरक्षा और सतत आर्थिक विकास सुनिश्चित सवालों जवाब ? क्या हम जानते कि हम एक अधिक समृद्ध दुनिया कैसे बनाएंगे ? '\",\n",
              "       \"चूंकि हम बच्चे हमें प्रचार साथ बमबारी गई थी कि रोमांटिक प्रेम आदर्श रिश्ता है। हॉलीवुड फ़िल्में डिज़्नी कार्टून और साहित्यिक कथा सभी प्रेमपूर्ण प्रेम विवाह संघ एक परम आवश्यकता रूप चित्रित कितना झूठ ? क्या संभव कि रोमांटिक प्रेम हमारी खोज वास्तव हमें आजीवन जोड़ी बंधन बनाने रोक रही ? भावनात्मक जड़ बारे सोचते रोमांटिक प्रेम धारणा सवाल उठाना शुरू दिया। प्यार एक क्षणभंगुर भावना और सभी भावनाओं आकाश बादलों आता और चला जाता है। मुझे एक भावना आधार जीवन साथी चयन क्यों सिखाया ? मुझे निश्चित रूप खरीदते समय नौकरी आवेदन समय व्यक्तिगत वित्त भावनाओं उपयोग प्रोत्साहित नहीं जाता ऐसे इंसान चुनने बात आती शेष जीवन बिताने हूं तो ' उन सभी बड़े निर्णय भावना उपयोग स्थापना कथा सलाह दी जाती है। एक और प्रमुख सुराग कि रोमांटिक प्रेम साथी चुनने एक बचकानी रणनीति तथ्य कि व्यवस्थित विवाह देशों जहां भागीदारों विशुद्ध रूप व्यावहारिक मामलों आधार चुना जाता तलाक दर कम जहां उन देशों रोमांटिक प्रेम इस्तेमाल साथी चुनने जाता ( ) । जबकि समाज तलाक कई संयोग कि रोमांटिक प्रेम धारणाओं ज्यादा प्रभावित देशों तलाक दर ज्यादा है। रोमांस आविष्कार पता चला कि शादी जोड़ी बंधन एक पूर्व शर्त रूप प्यार उपयोग इच्छा एक आविष्कार निर्माण परंपरा और आस्तिक प्राधिकरण नष्ट जड़ें थीं। स्वच्छंदतावाद एक आंदोलन जो वीं शताब्दी शुरू न केवल व्यक्तियों बल्कि राष्ट्रों साथ-साथ व्यक्तिवाद एक केंद्रीय थीसिस आगे रोमांटिक प्रेम रखा। चाहता कि पुराने नियमों और परंपराओं ध्यान हटाकर ध्यान केंद्रित कि कैसा महसूस हैं। आंदोलन मुख्य रूप बुर्जुआ युवाओं आया आदर्शवादी लेखन परिवार धन इस्तेमाल किया। … रूमानी आन्दोलन बुर्जुआ सम्मेलनों बुर्जुआ समाज और नैतिकता विरोध ज्यादा नहीं था। चरम और तेजतर्रार और असामान्य और हिंसक जोखिम ग्राकेट बनने इच्छा हर युवा रोमांटिक थी। रोमैंटिक वास्तव बुर्जुआ मूल जो छाया भागने भरसक कोशिश थे। ( स्रोत ) [ ] रोमैंटिक्स मानना \\u200b\\u200bथा कि बुर्जुआ समाज स्थापित शीत अमूर्त नियमों और अनुष्ठानों बजाय पुरुषों और महिलाओं गर्म भावनाओं निर्देशित जाना चाहिए। ( स्रोत वे आधुनिक सामाजिक न्याय योद्धाओं आवाज जिनमें कई ट्रस्ट फंड बेबी जो `` विशेषाधिकार `` और `` असमानता `` खिलाफ बाहर निकलते और बिना कमाए धनवान मनोवैज्ञानिक दर्द राहत पाते हैं। तथ्य साथ कि एसजेडब्ल्यू तर्क भावनाओं ट्रम्प देखने स्पष्ट कि रोमांटिकवादी कैसे प्रोटो-एसजेडब्ल्यू जिनके व्यक्तिगत विचार सिर्फ जो परंपरा विनाश प्रबुद्धता आवश्यकता थी। प्रेम संबंधों परिभाषित जाना चाहिए रोमांटिक युग साहचर्य प्रेम साहित्य और ऐतिहासिक लेखन अक्सर वर्णित रूप था। भावुक प्यार एक उत्तेजना-चालित भावना जो अक्सर लोगों खुशी चरम भावना देता और लोगों पीड़ा भावनाओं दे है। साथी प्रेम रूप जो लोगों बीच एक स्थिर बंधन बनाता और लोगों शांति भावना देता है। वैज्ञानिकों भावुक प्रेम अवस्था `` कोकीन `` रूप वर्णित क्योंकि उस चरण दौरान मस्तिष्क एक न्यूरोट्रांसमीटर डोपामाइन जारी जैसे कि कोकीन उपयोग है। ( स्रोत ) पुराने नियम गीतों अलावा लेखकों भावुक प्रेम बारे निस्संदेह बहाना प्रोत्साहित नहीं और शून्य सबूत कि उपयोग नए विवाह बनाने प्रमुख कारक रूप भावुक प्रेम हम प्रयास महसूस कि एक रोमांचक बवंडर बह गए बज़फीड गोर विवरण प्रकाशित ईट प्रेयर लव जैसी बेस्टसेलर एक महिला लिखी गई जो तलाक गले लगा रही है। रोमांटिक युग महिलाओं रोमांटिक प्रेम बढ़ाने एक बड़ी भूमिका निभाई और वे ऐसा क्यों नहीं करेंगे ? गैर-कम्फ़र्टल अल्फ़ा पुरुष बनाई गई उत्तेजना बह जाने मज़ा कहीं अधिक कि पति राजा और ईश्वर समक्ष प्रतिदिन कर्तव्यों हैं। महिलाओं उत्साह जिम्मेदारी बीच चयन मौका और हम जानते कि उन्होंने क्या चुना है। रोमांटिक युग काम पूर्ववर्ती कार्यों भिन्न उन्होंने व्यापक दर्शकों बात थी आंशिक रूप पुस्तकों अधिक वितरण दर्शाते क्योंकि अवधि दौरान लागत कमी आई थी। रोमांटिक अवधि महिला लेखकों और महिला पाठकों वृद्धि देखी गई। ( स्रोत ) आधुनिक युग रोमांटिक प्रेम धारणा दोगुना यहूदी मनोवैज्ञानिक रॉबर्ट स्टर्नबर्ग प्रेम लोकप्रिय त्रिकोणीय सिद्धांत प्रस्ताव अक्सर आज प्रेम आदर्श परिभाषित रूप उपयोग जाता है। सिद्धांत बताते नुकसान पहुँचाया कि एक सफल रिश्ते प्यार तीनों रूपों बराबर आवश्यकता है। जो एक परिचयात्मक मनोविज्ञान पाठ्यक्रम लेता जो एक पॉप मनोविज्ञान किताब पढ़ता सिद्धांत अवगत कराया जाएगा और सोचकर चलना होगा कि रिश्ते जुनून आवश्यकता है। नहीं तो अनुमान कि संबंध अब `` घाघ `` नहीं और आदर्श कम है। मानते कि एक शादी रोमांटिक प्यार और जुनून आवश्यक बाहर निकलना आसान जाता क्योंकि एक महिला अब `` जुनून महसूस नहीं `` तो जानकर दूर चली जाएगी कि स्टर्नबर्ग जैसे विशेषज्ञ बात सहमत होंगे कि संबंध खराब और अब बचत लायक नहीं है। और जो आधुनिक महिलाएं ड्रॉ रही हैं। उन्होंने शादी प्रतिज्ञा एक घृणित उपेक्षा दिखाई विशेष रूप महसूस कि वे % तलाक शुरुआत हैं। स्वच्छंदतावाद और राष्ट्रवाद उदय राष्ट्रवाद रोमांटिक युग बाहर आया और भावुक प्रेम एक गलती थी तो क्या मतलब राष्ट्रवाद एक गलती ? स्वच्छंदतावाद प्रमुख विचारों और स्थायी विरासतों एक राष्ट्रवाद दावा जो रोमांटिक कला और राजनीतिक दर्शन एक केंद्रीय विषय बन गया। आंदोलन शुरुआती हिस्सों राष्ट्रीय भाषाओं और लोककथाओं विकास ध्यान केंद्रित और स्थानीय रीति-रिवाजों और परंपराओं महत्व साथ उन आंदोलनों जो यूरोप नक्शे परिभाषित करेंगे और राष्ट्रीयता राष्ट्रवाद आत्म-निर्णय नेतृत्व करेंगे। स्वच्छंदतावाद भूमिका अभिव्यक्ति और अर्थ प्रमुख वाहनों एक था। [ … ] स्वतंत्रता देशभक्ति राष्ट्रवाद क्रांति और सशस्त्र संघर्ष काल कलाओं लोकप्रिय विषय बने। ( स्रोत ) करीब निरीक्षण देखना आसान कि आज सत्तारूढ़ एजेंडा वैश्विकता अनिवार्य रूप `` विश्व राष्ट्रवाद `` है। पड़ोसी प्यार बजाय और केवल वे जो अनोखी परंपराओं दौड़ साझा दुनिया हर प्यार क्योंकि सोचना बुरा कि एक ह्यूगो बॉस सूट और टुटी जर्मन व्यापारी बीच बड़े मतभेद एक लिप प्लेट साथ ग्रामीण एक अंगूर आकार। राष्ट्रवाद रोमांटिक आदर्श एडोल्फ हिटलर नहीं जॉर्ज सोरोस जो दुनिया हर प्यार हार्दिक मानवीय करुणा गहराई जोर देते हैं। आनुवांशिकी और स्थानीय बंधनों आधारित एक राष्ट्रवाद नागरिकों `` वैश्विक राष्ट्रवाद `` बेहतर संदेह नहीं करेगा उन लोगों देखभाल जो जैसे नहीं हैं। पुरुषों जीवन साथी कैसे चुनने चाहिए ? स्पष्ट कि लंबे समय संबंधों प्राथमिक मानक रूप रोमांटिक प्रेम और जुनून उपयोग विफलता और शायद व्यक्तिगत तबाही होगी। पिछले रिश्तों और उन महिलाओं गलतियों मूल्यांकन करके आसानी निष्कर्ष पहुंचेंगे जिनके पास तीव्र जुनून था। बजाय व्यावहारिकता दिन क्रम चाहिए। आपको मूल्यों विश्वासों और यौन इतिहास तौलकर ऐसी महिला तार्किक रूप मूल्यांकन चाहिए साथ एक आकस्मिक रिश्ते अधिक हैं। तुलना आसान क्योंकि हम जुनून महत्वपूर्ण मानने दिमाग लगा केवल अधिक समझ आता है। एक महिला खोजें एक नई नौकरी पाएंगे एक नया खरीदेंगे और उन महिलाओं सावधान रहें आपको व्यावहारिक मामलों अधिक जुनून आधार चुना है। पत्नी खोजने आपको ठंड लग जैसे एक व्यावसायिक भागीदार वास्तव है। परिवार दिन-प्रतिदिन जीवन प्रेम कहीं अधिक व्यवसाय और अर्थशास्त्र और इसलिए आपको निष्कर्ष पहुंचना चाहिए कि स्थिर बनाने आपको क्या चाहिए। हालांकि समझें कि हम एक पारंपरिक और पितृसत्तात्मक समाज नहीं रहते जो हमें एक गुणवान महिला खोज सहायता है। बजाय समाज सशक्तिकरण और स्वतंत्रता नाम महिलाओं खुद यौन और शारीरिक रूप भ्रष्ट प्रोत्साहित जिससे हमारी खोज अत्यधिक कठिन रही है। उन लागतों एक जो हमें आधुनिक दुनिया रहने भुगतान है। पुरुष उबरने सक्षम होंगे पुरुष ऐसा नहीं पाएंगे और महिला साथ परिवार बना खोज असफल रहेंगे। कम कम अब हम ज्ञान लैस कि अधिक सफल दीर्घकालिक संबंध बनाने क्या चाहिए। पेट रोमांटिक प्रेम तितलियाँ नहीं व्यावहारिकता बात है। तार्किक रूप अतीत मूल्यों और विश्वासों मूल्यांकन कि भविष्य किस व्यवहार करेगा ध्वनि भविष्यवाणी है। मूल्यांकन एक तार्किक निर्णय आएगा जो भावनाओं निर्भर बजाय जो हवा दिशा रूप आसानी बदल जाता निर्भर है। और पढ़ें : एक महिला बिना शर्त प्यार असंभव\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kMxtYZDo3KL",
        "outputId": "9c591af3-f7bd-4a27-9fa5-d86bed409eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBczDlhjRlvI",
        "outputId": "dea44a7c-925c-47bd-e6a2-95fe87bd9acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True) #bert-base-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fj6N87kRu8w",
        "outputId": "0611bb1b-ccbe-40af-fb02-38daa0e04572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  ’ — ( ) — “ ‘ ’ ” — “ ! ! ! ” “ ” — “ — ! ” — : “ ? ” ? “ ’ ” “ ” “ ” “ ” : “ ’ ” “ ! ” ” ’ ” “ ” “ ” — “ ” — ’ “ ” “ ” ’ : ’ — — “ ” : — — : ’ ’ ’ “ ” — “ ” : ’ “ ” ’ ’ — “ ” “ ” : “ ” ’ “ ” “ ” ’ “ ” — — ’ “ ” ’ “ ” “ ’ ” “ ’ ” “ ’ ” “ ” — ’ “ ” “ ” ’ ’ ’ : “ ’ ” “ ” “ ’ ” “ ” — “ ” — “ ’ ” “ ” “ ” “ ’ “ — — — “ ” “ ” : “ ! ” — — “ ” ’ ’ “ ” : “ ” ’ “ ” “ ‘ ? ’ ‘ ’ ‘ ’ ’ ” “ ’ ”\n",
            "Token IDs: [101, 100, 100, 113, 114, 100, 100, 100, 100, 100, 100, 100, 106, 106, 106, 100, 100, 100, 100, 100, 100, 106, 100, 100, 131, 100, 136, 100, 136, 100, 100, 100, 100, 100, 100, 100, 100, 100, 131, 100, 100, 100, 100, 106, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 131, 100, 100, 100, 100, 100, 131, 100, 100, 131, 100, 100, 100, 100, 100, 100, 100, 100, 131, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 131, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 131, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 131, 100, 106, 100, 100, 100, 100, 100, 100, 100, 100, 100, 131, 100, 100, 100, 100, 100, 100, 100, 136, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 102]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "for sent in sentences:\n",
        "    # `encode` will:  (1) Tokenize the sentence.   (2) Prepend the `[CLS]` token to the start.  (3) Append the `[SEP]` token to the end. (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 500,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[1])\n",
        "print('Token IDs:', input_ids[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55X0t7OkR25g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "42ed150c-b557-47a9-f506-854d86f4b57c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "seq_len = [len(sen) for sen in input_ids]\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulZ-JIfLUlsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab24edaf-1995-4881-ec41-528a2f47636d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  500\n"
          ]
        }
      ],
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLDJorkfUsYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc9bfa0-5a49-485b-beef-16770f28ced8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 128 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\\Done.\n"
          ]
        }
      ],
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do padding.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# Set the maximum sequence length as 128 , as it should be slightly above 105\n",
        "MAX_LEN = 128\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "print('\\Done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQxO-LGzU1b-"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask. If a token ID is 0, then it's padding, set the mask to 0. If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EkgDZ9RU686"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training, 10% validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=123, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=123, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu-KJUZLWmNQ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJcQgduxVDFJ"
      },
      "outputs": [],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODcuFrh3WnLn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
        "batch_size = 32\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru7l0rqwWq71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906,
          "referenced_widgets": [
            "1cc0db7339bc4ab7bf96b68cb69f3a1f",
            "b78ad7511d614aeebeaa1c2a7f3108d4",
            "55a157f78be4495c9331b76982f8f484",
            "10c5e8f5dd724be096ada0c75d097a85",
            "1054fce53d004137b220da802efd5fab",
            "866033abeef744a8a7e5a3990a2c3a47",
            "62f939a0a3d1472493908f2cd8c1d467",
            "312b7ec742e94c9db9f35db68215e170",
            "c4b55f0a8c7344faba8be109b1cb5ab8",
            "218c240b33354ff1a4ea9680d9d46627",
            "62656d026c9f48f89318cabdcb39af33"
          ]
        },
        "outputId": "25154548-787b-4925-f612-847b9b784351"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc0db7339bc4ab7bf96b68cb69f3a1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykRgeOb8XAID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e31a92-2b10-41d8-ccbb-c07133567b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "print('==== Embedding Layer ====\\n')\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89DfoXjhXJZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce81c5e-b09d-44d6-de76-a3de11ba0a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 5\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k0ojxfpXN-N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP9px02TXQpH"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qej0yJlFXS2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25c40e2-6f98-45a8-81eb-5244a080737d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of     47.    Elapsed: 0:00:30.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of     47.    Elapsed: 0:00:28.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of     47.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of     47.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of     47.    Elapsed: 0:00:27.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:00:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation took: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "start=time.time()\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "\n",
        "        model.zero_grad()\n",
        "        # Perform a forward pass .This will return the loss .\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end. `loss` is a Tensor containing a single value\n",
        "        total_loss += loss.item()\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # Clip the norm of the gradients to 1.0. This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on our validation set.\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and  speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions. This will return the logits rather than the loss because we have not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\"\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model.\n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "end=time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLOBP6U6Xagg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "46e7c52a-6f20-4fda-9ae3-5256ff201347"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"c502ebb5-6a4d-4c68-a12b-2c04b7d064bd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c502ebb5-6a4d-4c68-a12b-2c04b7d064bd\")) {                    Plotly.newPlot(                        \"c502ebb5-6a4d-4c68-a12b-2c04b7d064bd\",                        [{\"hovertemplate\":\"index=%{x}\\u003cbr\\u003eLoss=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0,1,2,3,4],\"xaxis\":\"x\",\"y\":[0.5698125952101768,0.27757102964406316,0.1682956675662005,0.0938207883229281,0.04064651022843541],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Training loss of the Model\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c502ebb5-6a4d-4c68-a12b-2c04b7d064bd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "f = pd.DataFrame(loss_values)\n",
        "f.columns=['Loss']\n",
        "fig = px.line(f, x=f.index, y=f.Loss)\n",
        "fig.update_layout(title='Training loss of the Model',\n",
        "                   xaxis_title='Epoch',\n",
        "                   yaxis_title='Loss')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxvGSrTKXltE"
      },
      "outputs": [],
      "source": [
        "sentences = test.values\n",
        "labels = y_test.values\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "for sent in sentences:\n",
        "\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256\n",
        "                   )\n",
        "\n",
        "    input_ids.append(encoded_sent)\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2bU8eKfX5zI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d1dada5-eed9-42c7-acff-bbf3376a0df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 411 test sentences...\n",
            "DONE.\n"
          ]
        }
      ],
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "  logits = outputs[0]\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "print('DONE.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model,'/content/drive/MyDrive/NLP DATA/fakenews_classifier.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YpclvJ6HOPu",
        "outputId": "546d7ee5-676a-419d-fdc7-74e5c2db7440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/NLP DATA/fakenews_classifier.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ogga9P-KYBaH"
      },
      "outputs": [],
      "source": [
        "count=0\n",
        "guesses=[]\n",
        "actual=[]\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" and one column for \"1\"). Pick the label with the highest value and turn this in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "\n",
        "  #calculate accuracy\n",
        "  for j in range(len(pred_labels_i)):\n",
        "    if(pred_labels_i[j]==true_labels[i][j]):\n",
        "      count+=1\n",
        "    guesses.append(pred_labels_i[j])\n",
        "    actual.append(true_labels[i][j])\n",
        "\n",
        "\n",
        "accuracy = count/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXaNmPlzYKNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24486e51-1ca7-426a-9ebf-cfeda2994b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9124087591240876\n"
          ]
        }
      ],
      "source": [
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8yxCQcBYMKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88bf8ae3-26af-455a-e600-424a97b3440f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9124087591240876\n",
            "0.8817733990147784\n",
            "0.93717277486911\n",
            "0.9086294416243654\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "\n",
        "print(accuracy_score(actual, guesses))\n",
        "print(recall_score(actual, guesses))\n",
        "print(precision_score(actual, guesses))\n",
        "print(f1_score(actual, guesses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yOMWpixYOhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bb08fc-17b3-49d7-d7d5-443f043efadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "166.95828890800476\n"
          ]
        }
      ],
      "source": [
        "print(end-start)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1cc0db7339bc4ab7bf96b68cb69f3a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b78ad7511d614aeebeaa1c2a7f3108d4",
              "IPY_MODEL_55a157f78be4495c9331b76982f8f484",
              "IPY_MODEL_10c5e8f5dd724be096ada0c75d097a85"
            ],
            "layout": "IPY_MODEL_1054fce53d004137b220da802efd5fab"
          }
        },
        "b78ad7511d614aeebeaa1c2a7f3108d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866033abeef744a8a7e5a3990a2c3a47",
            "placeholder": "​",
            "style": "IPY_MODEL_62f939a0a3d1472493908f2cd8c1d467",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "55a157f78be4495c9331b76982f8f484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312b7ec742e94c9db9f35db68215e170",
            "max": 672247920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4b55f0a8c7344faba8be109b1cb5ab8",
            "value": 672247920
          }
        },
        "10c5e8f5dd724be096ada0c75d097a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218c240b33354ff1a4ea9680d9d46627",
            "placeholder": "​",
            "style": "IPY_MODEL_62656d026c9f48f89318cabdcb39af33",
            "value": " 672M/672M [00:06&lt;00:00, 260MB/s]"
          }
        },
        "1054fce53d004137b220da802efd5fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866033abeef744a8a7e5a3990a2c3a47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62f939a0a3d1472493908f2cd8c1d467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312b7ec742e94c9db9f35db68215e170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b55f0a8c7344faba8be109b1cb5ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "218c240b33354ff1a4ea9680d9d46627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62656d026c9f48f89318cabdcb39af33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}